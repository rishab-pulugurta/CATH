{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qx6JyLfkRkpO"
      },
      "outputs": [],
      "source": [
        "#installs\n",
        "!pip install biopython\n",
        "!pip install py3dmol\n",
        "!pip install transformers\n",
        "!pip install fair-esm\n",
        "!pip install scikit-learn\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import torch\n",
        "import esm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import io\n",
        "from google.colab import drive\n",
        "from transformers import EsmModel, EsmTokenizer, EsmConfig, AutoTokenizer\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from google.colab import drive\n",
        "import os\n",
        "from Bio.PDB import PDBParser\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch_geometric.data import Data\n",
        "import torch\n",
        "from torch_geometric.nn import GATConv, global_max_pool\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "\n",
        "#connect to drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "eCWgGwmnRsek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load in test data (at least need columns named 'sequences' and 'architecture')\n",
        "df = pd.read_csv('your test dataset path')"
      ],
      "metadata": {
        "id": "JmE5wFGPRt-8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load esm model\n",
        "esm_model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
        "batch_converter = alphabet.get_batch_converter()\n",
        "esm_model.eval()  # disables dropout for deterministic results"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9rT4dd8iS-e7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run embeddings\n",
        "sequence_embeddings = {}\n",
        "\n",
        "for sequence in tqdm(df['sequences']):\n",
        "\n",
        "    #standard esm calculations\n",
        "    batch_labels, batch_strs, batch_tokens = batch_converter([(\"\", sequence)])\n",
        "    batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        results = esm_model(batch_tokens, repr_layers=[33], return_contacts=True)\n",
        "    token_representations = results[\"representations\"][33].cpu()\n",
        "    del batch_tokens\n",
        "\n",
        "    avg_embedding = token_representations[0, 1 : batch_lens[0] - 1].mean(0)\n",
        "    sequence_embeddings[sequence] = avg_embedding"
      ],
      "metadata": {
        "id": "7uxiEhTlS--5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "\n",
        "#fit encoder on the architecture labels\n",
        "df['encoded_architecture'] = label_encoder.fit_transform(df['architecture'])"
      ],
      "metadata": {
        "id": "-tWd-efmR005"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unzip pdb files\n",
        "!unzip 'path to your pdb files zipped' -d /content/pdb_files #you can change output path to your preference as well"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vbeWNo-WU3I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run this to get coordinate and edges data\n",
        "\n",
        "pdb_dir = 'path to folder where all pdb files are stored' #assuming same format as what was given for training\n",
        "\n",
        "data_list = []\n",
        "\n",
        "parser = PDBParser(QUIET=True)\n",
        "\n",
        "pdb_files = os.listdir(pdb_dir)\n",
        "\n",
        "for pdb_file in tqdm(pdb_files, desc=\"Loading PDB files\"):\n",
        "    pdb_path = os.path.join(pdb_dir, pdb_file)\n",
        "    if os.path.isfile(pdb_path):\n",
        "        structure = parser.get_structure('protein', pdb_path)\n",
        "\n",
        "        atom_coords = []\n",
        "        atom_types = []\n",
        "        edge_index = []\n",
        "\n",
        "        for model in structure:\n",
        "            for chain in model:\n",
        "                for residue in chain:\n",
        "                    for atom in residue:\n",
        "                        atom_coords.append(atom.coord.tolist())\n",
        "                        atom_types.append(atom.element)\n",
        "\n",
        "        num_atoms = len(atom_coords)\n",
        "        edge_index = []\n",
        "\n",
        "        if num_atoms == 0:\n",
        "            continue\n",
        "\n",
        "        for i in range(num_atoms):\n",
        "            for j in range(i+1, num_atoms):\n",
        "                distance = np.linalg.norm(np.array(atom_coords[i]) - np.array(atom_coords[j]))\n",
        "                if distance < 5.0: #using 5 Angstroms from literature\n",
        "                    edge_index.append([i, j])\n",
        "                    edge_index.append([j, i])\n",
        "\n",
        "        x = torch.tensor(atom_coords, dtype=torch.float)\n",
        "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "        identifier = os.path.splitext(pdb_file)[0] #allows us to map back to cath_id\n",
        "\n",
        "        data = Data(x=x, edge_index=edge_index, pdb_id=identifier)\n",
        "\n",
        "        data_list.append(data)"
      ],
      "metadata": {
        "id": "ZgQMfdx9R22p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "structural_data_dict = {data.pdb_id: data for data in data_list}\n",
        "\n",
        "#store the structural Data\n",
        "df['structural_data'] = df['cath_id'].map(structural_data_dict)"
      ],
      "metadata": {
        "id": "ywhz_pWjSTdZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model to get structure embeddings (use classifier to train, only take embeddings from model)\n",
        "class GATClassifier(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_heads=8, dropout_rate=0.3):\n",
        "        super(GATClassifier, self).__init__()\n",
        "        self.conv1 = GATConv(in_channels, hidden_channels // num_heads, heads=num_heads)\n",
        "        self.conv2 = GATConv(hidden_channels, hidden_channels // num_heads, heads=num_heads)\n",
        "        self.conv3 = GATConv(hidden_channels, hidden_channels // num_heads, heads=num_heads)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "        #fully connected layers\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(hidden_channels, 320),\n",
        "            nn.ReLU(),\n",
        "            self.dropout,\n",
        "            nn.Linear(320, 128),\n",
        "            nn.ReLU(),\n",
        "            self.dropout,\n",
        "            nn.Linear(128, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        #get graph data\n",
        "        structure_data = data['Structure']\n",
        "        x, edge_index, batch = structure_data.x, structure_data.edge_index, structure_data.batch\n",
        "\n",
        "        #add skip connections\n",
        "        x1 = F.relu(self.conv1(x, edge_index))\n",
        "        x2 = F.relu(self.conv2(x1, edge_index)) + x1\n",
        "        x3 = self.conv3(x2, edge_index) + x2\n",
        "\n",
        "        #max pooling\n",
        "        x = global_max_pool(x3, batch)\n",
        "\n",
        "        #pass through fc layers\n",
        "        out = self.fc_layers(x)\n",
        "\n",
        "        return out, x"
      ],
      "metadata": {
        "id": "eRSj-4dSSh12"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "oFhrRP-KWSPO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initalize model for embeddings\n",
        "struct_model = GATClassifier(in_channels=3, hidden_channels=640, out_channels=10, num_heads=8).to(device)"
      ],
      "metadata": {
        "id": "Jq7d-wauSqpO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model path (you may need to change model path depending on how you are running the code)\n",
        "struct_path = 'checkpoints/structure_model.pt'\n",
        "struct_model.load_state_dict(torch.load(struct_path, map_location=device))"
      ],
      "metadata": {
        "id": "1wjsAOw9Wc3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#store structure embeddings (similar to what was done w sequence)\n",
        "\n",
        "struct_model.eval()\n",
        "\n",
        "struct_model = struct_model.to(device)\n",
        "\n",
        "structure_embeddings = {}\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx, row in tqdm(df.iterrows()):\n",
        "        #get structure and sequence data\n",
        "        structure_data = row['structural_data']\n",
        "        sequence = row['sequences']\n",
        "\n",
        "        structure_data = structure_data.to(device)\n",
        "\n",
        "        input_data = {'Structure': structure_data}\n",
        "\n",
        "        #get embeddings only\n",
        "        _, embedding = struct_model(input_data)\n",
        "\n",
        "        structure_embeddings[sequence] = embedding"
      ],
      "metadata": {
        "id": "jnKClCSdSVcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset class setup\n",
        "\n",
        "class SeqStructDataset(torch.utils.data.Dataset):\n",
        "   def __init__(self, df, sequence_embeddings, structure_embeddings):\n",
        "    super().__init__()\n",
        "    self.sequence_embeddings = sequence_embeddings\n",
        "    self.structure_embeddings = structure_embeddings\n",
        "    self.df = df\n",
        "\n",
        "   def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "   def __getitem__(self, index):\n",
        "    prot, architecture = self.df.loc[index][['sequences', 'encoded_architecture']]\n",
        "    prot_embedding = self.sequence_embeddings[prot]\n",
        "    structure_embedding = self.structure_embeddings[prot].squeeze(0)\n",
        "    architecture = torch.tensor(architecture, dtype=torch.long)\n",
        "\n",
        "\n",
        "    return_dict = {\n",
        "        \"Protein\": prot,\n",
        "        \"Sequence Input\": prot_embedding,\n",
        "        \"Structure Input\": structure_embedding,\n",
        "        \"Architecture\": architecture\n",
        "    }\n",
        "\n",
        "    return return_dict"
      ],
      "metadata": {
        "id": "A_kVaf-mSu2m"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sequence + structure attention model\n",
        "\n",
        "class SeqStructureClassifier(nn.Module):\n",
        "    def __init__(self, num_classes, sequence_embedding_dim=1280, structure_embedding_dim=640):\n",
        "        super(SeqStructureClassifier, self).__init__()\n",
        "\n",
        "        #self-attention layers for sequence and structure\n",
        "        self.sequence_attention = nn.MultiheadAttention(embed_dim=sequence_embedding_dim, num_heads=4, batch_first=True)\n",
        "        self.structure_attention = nn.MultiheadAttention(embed_dim=structure_embedding_dim, num_heads=4, batch_first=True)\n",
        "\n",
        "        #fully connected layers\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear((sequence_embedding_dim + structure_embedding_dim) * 2, 1280),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1280, 640),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(640, 320),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(320, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, sequence_embedding, structure_embedding):\n",
        "\n",
        "        #reshape embeddings\n",
        "        sequence_embedding = sequence_embedding.unsqueeze(1)\n",
        "        structure_embedding = structure_embedding.unsqueeze(1)\n",
        "\n",
        "        #apply self-attention to sequence and structure embeddings\n",
        "        sequence_attention_output, _ = self.sequence_attention(sequence_embedding, sequence_embedding, sequence_embedding)\n",
        "        structure_attention_output, _ = self.structure_attention(structure_embedding, structure_embedding, structure_embedding)\n",
        "\n",
        "        #concat original + attention embeddings\n",
        "        sequence_combined = torch.cat((sequence_embedding.squeeze(1), sequence_attention_output.squeeze(1)), dim=1)\n",
        "        structure_combined = torch.cat((structure_embedding.squeeze(1), structure_attention_output.squeeze(1)), dim=1)\n",
        "\n",
        "        #concatenate sequence and structure embeddings\n",
        "        combined = torch.cat((sequence_combined, structure_combined), dim=1)\n",
        "\n",
        "        #pass through fc layers\n",
        "        output = self.fc_layers(combined)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "cW_sxnUNTi5Y"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#setup\n",
        "test_dataset = SeqStructDataset(df, sequence_embeddings, structure_embeddings)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "wnCGjIkjTzVR"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initalize model\n",
        "final_model = SeqStructureClassifier(num_classes=10)\n",
        "\n",
        "#best model ((you may need to change model path depending on how you are running the code))\n",
        "model_path = 'checkpoints/seq_struct.pt'\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "final_model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "final_model.to(device)\n",
        "final_model.eval()"
      ],
      "metadata": {
        "id": "4okZ4HMkT9EI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predict on test set\n",
        "\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "all_sequences = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
        "        sequence_inputs = batch[\"Sequence Input\"].to(device)\n",
        "        structure_inputs = batch[\"Structure Input\"].to(device)\n",
        "        labels = batch[\"Architecture\"].to(device)\n",
        "        sequences = batch[\"Protein\"]\n",
        "\n",
        "        #get predictions\n",
        "        outputs = final_model(sequence_inputs, structure_inputs)\n",
        "        predictions = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        all_predictions.extend(predictions.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_sequences.extend(sequences)\n",
        "\n",
        "#decode predictions\n",
        "decoded_predictions = label_encoder.inverse_transform(all_predictions)\n",
        "decoded_labels = label_encoder.inverse_transform(all_labels)\n",
        "\n",
        "#metrics\n",
        "accuracy = accuracy_score(decoded_labels, decoded_predictions)\n",
        "precision = precision_score(decoded_labels, decoded_predictions, average='weighted')\n",
        "recall = recall_score(decoded_labels, decoded_predictions, average='weighted')\n",
        "\n",
        "for seq, pred, true_label in zip(all_sequences, decoded_predictions, decoded_labels):\n",
        "    print(f\"Sequence: {seq}\")\n",
        "    print(f\"Predicted Class: {pred}\")\n",
        "    print(f\"True Class: {true_label}\\n\")\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "cPCf-sMIURTE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}